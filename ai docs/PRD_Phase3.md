# CollabCanvas - Product Requirements Document (Phase 3)

## Executive Summary

**Mission:** Transform CollabCanvas into the first collaborative design tool with conversational AI capabilities by adding an intelligent agent that interprets natural language commands and executes canvas operations in real-time.

**Key Innovation:** Users can create complex layouts by describing them ("create a login form") instead of manually placing objects, while maintaining seamless real-time collaboration with team members.

**Core Principle:** AI operations are standard canvas operations—they sync to all users via existing Firebase infrastructure with zero special handling.

---

## Phase 3 Decisions Summary (FINALIZED)

**These decisions shape the entire Phase 3 implementation:**

1. **API Infrastructure:** Firebase Cloud Functions (already using Firebase Hosting)
2. **Tool Execution:** Client-side via Canvas Context (simpler, reuses existing code)
3. **Command Queue:** Per-canvas FIFO queue (prevents multi-user conflicts)
4. **Context Optimization:** Selected objects + recently created (for 100+ object canvases)
5. **Complex Templates:** Dynamically generated by GPT-4 (no hard-coding, more flexible)
6. **Undo System:** Deferred to Phase 4 (too complex for initial implementation)
7. **Rate Limiting:** None (personal project, no quota concerns)
8. **Visual Feedback:** Simple—only edit attribution badge + loading spinner in chat
9. **Command History:** Per-canvas, visible to all team members
10. **Multi-Step Progress:** Only visible to requesting user (keeps UI clean for others)
11. **Error Handling:** Inline in chat (natural conversation flow)
12. **Cost Management:** Not a concern (personal project, monitoring only)

**Simplified Scope = Faster Implementation:**

- Target: 4-5 weeks instead of 6-8 weeks
- Removed: Undo, rate limiting, ghost previews, progress bars, ⚡ icons
- Focus: Core AI functionality with clean, simple UX

---

## Current State Assessment

### Phase 1 & 2 Achievements (Completed)

**Infrastructure:**

- ✅ Zero data loss with offline queue (5-10 min window)
- ✅ Atomic transactions for conflict resolution
- ✅ Connection status monitoring
- ✅ Last edit attribution system

**Creative Tools:**

- ✅ 5 shape types: Rectangle, Circle, Star, Line, Text
- ✅ Stroke customization and opacity controls
- ✅ Rotation and multi-select
- ✅ Font formatting for text objects

**Workflow Features:**

- ✅ 10+ keyboard shortcuts
- ✅ Clipboard operations (copy, paste, cut, duplicate)
- ✅ Layers panel with drag-to-reorder
- ✅ Alignment and distribution tools
- ✅ Export (PNG 2x, SVG vector)

**Collaboration:**

- ✅ Real-time sync (<100ms objects, <50ms cursors)
- ✅ Multiplayer presence and cursors
- ✅ Visual selection sync between users

### Phase 3 Opportunity

CollabCanvas has established reliable infrastructure and comprehensive design tools. Phase 3 leverages this foundation to add AI-powered design assistance, dramatically reducing time to create common layouts while maintaining our collaborative edge.

---

## Phase 3 Vision

### User Story: AI-Powered Collaborative Design

**Sarah (Product Designer) uses AI for rapid prototyping:**

1. Opens CollabCanvas, types in AI chat: "Create a mobile app login screen"
2. AI generates complete login form (title, input fields, button, link) in 2 seconds
3. Sarah: "Make the button bigger and move it down 20 pixels"
4. AI adjusts instantly
5. **Teammate Marcus sees everything appear in real-time** on his screen
6. Marcus: "Add a 'Sign up' link below the login button"
7. AI adds the link, both see the update

**Result:** 2 minutes to create complete layout vs. 15 minutes of manual work, with perfect team synchronization.

---

## Strategic Goals

### Goal 1: Natural Language Design Interface

Enable users to create and manipulate canvas objects using conversational commands, reducing cognitive load and accelerating workflow.

### Goal 2: Seamless Multi-User AI Integration

AI operations appear identical to manual edits for all collaborators, with proper attribution showing "AI Agent (requested by [User])".

### Goal 3: Production-Ready AI System

Reliable function calling with >95% success rate, <2s latency for simple commands, <5s for complex operations.

### Goal 4: Cost-Effective AI Usage

Smart context optimization and rate limiting to maintain <$0.01 per command while handling canvases with 500+ objects.

---

## User Stories

### Primary Persona: Product Designer (Sarah)

**Context:** Sarah designs landing pages with her remote team and needs to rapidly prototype layouts.

**Critical Needs:**

- "I want to create common UI patterns instantly without clicking 20 times" → **Complex layout commands**
- "I need my teammates to see what AI creates in real-time" → **Transparent collaboration**
- "I want to iterate quickly with AI understanding my context" → **Conversational refinement**
- "I need AI to understand 'make it bigger' without specifying what" → **Context awareness**

### Secondary Persona: Design Team Lead (Marcus)

**Context:** Marcus reviews designs and guides junior designers on best practices.

**Critical Needs:**

- "I want to see AI command history to understand design decisions" → **Command history panel**
- "I need to undo AI mistakes quickly without manual cleanup" → **Grouped undo for AI operations**
- "I want to suggest AI commands to teammates during collaboration" → **Command suggestions**

---

## Phase 3 Requirements

## Section 1: Natural Language Understanding

### 1.1 Command Categories

#### Creation Commands

**Capability:** Generate objects from natural language descriptions

**Examples:**

- "Create a red circle at position 100, 200"
- "Add a text that says 'Welcome' at the center"
- "Make a 200x300 blue rectangle"

**Requirements:**

- Support all 5 shape types (Rectangle, Circle, Star, Line, Text)
- Parse color names, hex codes, and RGB values
- Default to canvas center (5000, 5000) if position not specified
- Validate all parameters before execution

---

#### Manipulation Commands

**Capability:** Modify existing objects using references

**Examples:**

- "Move the red circle to 400, 500"
- "Resize the rectangle to be twice as big"
- "Rotate the text 45 degrees"
- "Change the blue square to green"

**Requirements:**

- Reference objects by color, type, or position
- Support relative transformations ("twice as big", "20 pixels down")
- Handle ambiguous references with clarifying questions
- Prevent out-of-bounds operations

---

#### Layout Commands

**Capability:** Arrange multiple objects with intelligent spacing

**Examples:**

- "Arrange these shapes in a horizontal row with 20px spacing"
- "Create a 3x3 grid of 100px squares"
- "Align all circles to the left edge"
- "Distribute these elements evenly vertically"

**Requirements:**

- Leverage existing alignment/distribution tools
- Support selection references ("these shapes" = currently selected)
- Apply consistent spacing (default: 20px)
- Maintain relative object positions during transformations

---

#### Complex Multi-Step Commands

**Capability:** Break down high-level design tasks into atomic operations

**Examples:**

- "Create a login form with username and password fields"
- "Build a navigation bar with 4 menu items"
- "Make a card layout with title, image placeholder, and description"

**Requirements:**

- AI plans multi-step execution (7-10 operations per complex command)
- Show progress during execution ("Creating login form... 3/7 steps")
- Apply design best practices (proper spacing, alignment, hierarchy)
- Use theme colors consistently (#3B82F6 for primary actions)

**Component Templates to Support:**

- Login forms (title, labels, inputs, button, link)
- Navigation bars (background, menu items, logo area)
- Card layouts (container, title, image placeholder, text)
- Pricing tables (columns, headers, features, CTA buttons)
- Mobile app headers (logo, menu icon, title)

---

#### Query Commands

**Capability:** Provide information about current canvas state

**Examples:**

- "How many rectangles are on the canvas?"
- "What color is the selected shape?"
- "List all objects created by Sarah"

**Requirements:**

- Read-only operations (no state changes)
- Return structured data in conversational format
- Support filtering by type, color, creator, date range

---

#### Selection Commands

**Capability:** Programmatically select objects based on criteria

**Examples:**

- "Select all red circles"
- "Select the largest rectangle"
- "Clear selection"

**Requirements:**

- Update local selection state (existing multi-select system)
- Support complex queries (color + type, size comparisons)
- Sync selection to presence system (other users see highlights)

---

### 1.2 Context Awareness

**Requirements:**

- AI receives summarized canvas state with every command
- References previous commands in conversation ("make it bigger" = last created object)
- Understands relative positioning ("to the right of the circle")
- Knows current selection state and viewport position

**Canvas State Context Structure:**

**For Small Canvases (<100 objects):** Full state

```json
{
  "objects": [
    {
      "id": "obj-1",
      "type": "rectangle",
      "x": 100,
      "y": 200,
      "width": 150,
      "height": 100,
      "fill": "#3B82F6"
    },
    {
      "id": "obj-2",
      "type": "circle",
      "x": 400,
      "y": 300,
      "radius": 50,
      "fill": "#EF4444"
    }
  ],
  "selectedIds": ["obj-1"],
  "viewport": { "zoom": 1.0, "panX": 0, "panY": 0 }
}
```

**For Large Canvases (100-500 objects):** Summarized state

```json
{
  "objectCount": 150,
  "objectTypes": { "rectangle": 80, "circle": 50, "text": 15, "star": 5 },
  "selectedObjects": [
    {
      "id": "obj-1",
      "type": "rectangle",
      "x": 100,
      "y": 200,
      "fill": "#3B82F6"
    }
  ],
  "recentlyCreated": [
    {
      "id": "obj-150",
      "type": "text",
      "text": "Header",
      "createdAt": 1697123456789
    }
  ]
}
```

**For Very Large Canvases (>500 objects):** Minimal state

```json
{
  "objectCount": 750,
  "objectTypes": { "rectangle": 400, "circle": 250, "text": 75, "star": 25 },
  "selectedObjects": [
    /* selected only */
  ],
  "recentlyCreated": [
    /* last 5 only */
  ]
}
```

**Cost Optimization:**

- <100 objects: ~2000 tokens (~$0.02/command)
- 100-500 objects: ~500 tokens (~$0.005/command)
- > 500 objects: ~250 tokens (~$0.003/command)

---

## Section 2: Function Calling Architecture

### 2.1 Tool-Based Execution

**Design Principle:** AI calls predefined tools mapped 1:1 to existing Canvas Context functions—no logic duplication.

### Core Tools (16 Total)

#### Creation Tools

- **createShape**(type, x, y, width, height, color, stroke?, strokeWidth?)
  - Maps to: `CanvasContext.createRectangle()`, `createCircle()`, `createStar()`, `createLine()`
  - Validation: Type must be valid, position within bounds (0-10000), color must be hex
- **createText**(text, x, y, fontSize?, fontFamily?, color?)
  - Maps to: `CanvasContext.createText()`
  - Validation: Text length <1000 chars, fontSize 8-72, fontFamily from allowed list

#### Manipulation Tools

- **moveShape**(shapeId, x, y)
  - Maps to: `CanvasContext.updateObject()` with position changes
- **resizeShape**(shapeId, width, height)
  - Maps to: `CanvasContext.updateObject()` with size changes
- **rotateShape**(shapeId, degrees)
  - Maps to: `CanvasContext.updateObject()` with rotation
- **deleteShape**(shapeId)
  - Maps to: `CanvasContext.deleteObject()`

#### Styling Tools

- **updateShapeStyle**(shapeId, fill?, stroke?, strokeWidth?, opacity?)
  - Maps to: `CanvasContext.updateObject()` with style properties
- **updateTextStyle**(shapeId, fontSize?, fontWeight?, fontFamily?)
  - Maps to: `CanvasContext.updateObject()` with text properties

#### Layout Tools

- **arrangeHorizontal**(shapeIds[], spacing)
  - Uses existing alignment helpers
- **arrangeVertical**(shapeIds[], spacing)
  - Uses existing alignment helpers
- **createGrid**(rows, cols, cellWidth, cellHeight, spacing)
  - Combines createShape + arrangeHorizontal/Vertical
- **alignShapes**(shapeIds[], alignment: 'left'|'center'|'right'|'top'|'middle'|'bottom')
  - Maps to existing alignment functions
- **distributeShapes**(shapeIds[], direction: 'horizontal'|'vertical')
  - Maps to existing distribution functions

#### Query Tools (Read-Only)

- **getCanvasState**()
  - Returns current objects for AI context
- **findShapesByColor**(color)
  - Filters objects by fill color
- **findShapesByType**(type)
  - Filters objects by shape type
- **getSelectedShapes**()
  - Returns currently selected object IDs

---

### 2.2 Parameter Validation

**Requirements:**

- All tool parameters validated with Zod schemas before execution
- Invalid parameters rejected with helpful error messages
- Bounds checking for positions (0-10000 canvas size)
- Color validation (hex codes, named colors, RGB)
- Reference validation (object IDs must exist)

**Validation Examples:**

```typescript
// Zod schema for createShape tool
const createShapeSchema = z.object({
  type: z.enum(["rectangle", "circle", "star", "line"]),
  x: z.number().min(0).max(10000),
  y: z.number().min(0).max(10000),
  width: z.number().min(10).max(5000),
  height: z.number().min(10).max(5000),
  color: z.string().regex(/^#[0-9A-F]{6}$/i),
  stroke: z
    .string()
    .regex(/^#[0-9A-F]{6}$/i)
    .optional(),
  strokeWidth: z.number().min(0).max(20).optional(),
});
```

---

## Section 3: Real-Time Collaboration Integration

### 3.1 Transparent Synchronization

**Requirement:** AI-generated content syncs identically to manually created objects—no special handling required.

**Implementation:**

- AI tools call existing Canvas Context functions (createRectangle, updateObject, etc.)
- Canvas Context saves to Firebase Realtime Database at `/canvases/default/objects/`
- All users receive updates via existing Firebase listeners (<100ms)
- No AI-specific sync logic needed

### 3.2 AI Operation Attribution

**Requirement:** Clearly indicate which objects were created/modified by AI

**Data Model Enhancement:**

```typescript
interface CanvasObject {
  // ... existing fields
  createdBy: string; // "user-123" | "ai-agent"
  aiOperationId?: string; // Groups objects from same AI command (for undo)
  aiRequestedBy?: string; // User who issued the AI command
}
```

**Visual Attribution:**

- Edit attribution badge shows "AI Agent (requested by Sarah Chen)"
- Tooltip on hover: "Created by AI Agent at Sarah's request, 2m ago"
- Small ⚡ icon on AI-generated objects (visible on hover)

### 3.3 Multi-User Command Queueing

**Problem:** Two users issuing AI commands simultaneously could cause conflicts

**Solution:** Per-canvas FIFO queue ensures sequential execution

**Implementation:**

```typescript
class AICommandQueue {
  private queue: AICommand[] = [];
  private isProcessing: boolean = false;

  async enqueue(command: AICommand): Promise<void> {
    this.queue.push(command);
    if (this.queue.length > 5) {
      throw new Error("Command queue full (max 5). Please wait.");
    }
    await this.processQueue();
  }

  private async processQueue(): Promise<void> {
    if (this.isProcessing || this.queue.length === 0) return;

    this.isProcessing = true;
    const command = this.queue[0];

    try {
      await this.executeCommand(command);
      this.queue.shift();
    } finally {
      this.isProcessing = false;
      if (this.queue.length > 0) {
        await this.processQueue();
      }
    }
  }
}
```

**User Experience:**

- User A issues command → executes immediately
- User B issues command simultaneously → queued with message "1 command ahead of you"
- Commands execute in order (A's completes, then B's starts)
- Max queue length: 5 commands (6th rejected with error)
- Timeout: 30 seconds per command (then cancellable)

---

## Section 4: AI System Architecture

### 4.1 Technology Stack

**AI Provider:** OpenAI GPT-4 Turbo (via Vercel AI SDK)

**Why GPT-4 over GPT-3.5:**

- Superior function calling accuracy (critical for reliable tool execution)
- Better understanding of complex multi-step commands
- More reliable parameter extraction and validation
- Handles ambiguous commands with clarifying questions

**API Architecture:** Server-Side (Firebase Cloud Functions)

**Why Firebase Functions:**

- **Security:** API keys never exposed to client
- **Ecosystem integration:** Direct access to Firebase Auth and Realtime Database
- **Simple deployment:** Already using Firebase Hosting
- **Logging:** Track all AI operations for debugging/analytics
- **Context optimization:** Summarize large canvas states server-side

### 4.2 Client-Server Flow

```
User types command in chat panel
         ↓
Frontend validates input (length check)
         ↓
POST /api/ai-chat (Firebase Cloud Function)
  - message: "Create a red circle"
  - canvasId: "default"
  - userId: "user-123"
  - conversationHistory: [previous messages]
         ↓
Server authenticates user (Firebase Auth)
         ↓
Server loads canvas state from Firebase
         ↓
Server summarizes canvas state (if >100 objects)
  - <100 objects: Full state
  - 100+ objects: Selected objects + recently created only
         ↓
Server calls OpenAI GPT-4 with:
  - System prompt (role + guidelines)
  - Canvas state context
  - User message
  - 16 function calling tools
         ↓
GPT-4 returns tool calls (JSON)
[
  {
    "name": "createShape",
    "arguments": {
      "type": "circle",
      "x": 100,
      "y": 200,
      "width": 100,
      "height": 100,
      "color": "#EF4444"
    }
  }
]
         ↓
Server validates tool call parameters (Zod schemas)
         ↓
Server returns tool calls + AI response to client
         ↓
Client executes tools sequentially via Canvas Context
  - createRectangle(), updateObject(), etc.
  - Uses existing offline queue if disconnected
         ↓
Canvas Context saves to Firebase (existing sync)
         ↓
All users see updates in real-time (<100ms)
```

### 4.3 System Prompt Design

**Role Definition:**

```
You are an AI assistant for CollabCanvas, a collaborative design tool.
You help users create and manipulate shapes on a shared canvas using natural language.

Available shapes: rectangle, circle, star, line, text
Canvas size: 10000x10000px (origin at top-left: 0,0)
Default colors: #3B82F6 (blue), #EF4444 (red), #10B981 (green), #F59E0B (amber), #8B5CF6 (purple)
```

**Behavioral Guidelines:**

```
When executing commands:
1. Parse user intent carefully—ask clarifying questions inline if ambiguous
2. Use appropriate tools for the task (prefer single tool over multiple if possible)
3. For complex commands (e.g., "login form"), dynamically plan logical steps
4. Always validate parameters (colors must be hex, positions within bounds)
5. Provide friendly confirmation messages ("Created 3 blue circles in a row")
6. If a command fails, explain why and suggest alternatives

Context awareness:
- Reference the current canvas state provided
- Use "the blue circle" to reference objects by color/type
- Default to canvas center (5000, 5000) if position not specified
- When creating multiple objects, space them 20px apart by default

Complex commands:
- Dynamically generate layouts for common UI patterns (login forms, nav bars, cards, etc.)
- Apply design best practices: proper spacing (16-20px), alignment, hierarchy
- Use theme colors consistently: #3B82F6 (primary blue), #EF4444 (red), #10B981 (green)
- For forms: labels above inputs, buttons below, reasonable input widths (300px)
- For navigation: horizontal layout, 20px spacing between items, centered text
```

---

### 4.4 ReAct Pattern for Multi-Step Reasoning

**Problem Statement:**

Single-pass AI execution cannot handle query-dependent operations where the AI needs to:

1. First query the canvas state (find objects by criteria)
2. Then act on the query results (delete, move, or modify those objects)

**Example Limitations (Current System):**

- "Delete all green shapes" → AI calls `findShapesByColor` but cannot follow up with `deleteShape`
- "Move all circles to the right" → AI finds circles but cannot move them
- "Make all red rectangles blue" → AI finds shapes but cannot change their color

**Solution: ReAct (Reason + Act) Loop**

Implement an iterative feedback loop where:

1. AI reasons about the task and calls tools
2. Tools execute and return results
3. Results feed back into AI for next reasoning step
4. Loop continues until task is complete or max iterations reached

---

#### 4.4.1 ReAct Architecture

**Execution Flow:**

```
User: "Delete all green shapes"

┌─────────────────────────────────────────────────────────────┐
│ Iteration 1: Query Phase                                     │
├─────────────────────────────────────────────────────────────┤
│ AI analyzes: "I need to find green shapes first"            │
│ Tool calls: [findShapesByColor("green")]                    │
│ Executes: Returns ["shape-1", "shape-2", "shape-3"]        │
│ Result → Feed back to AI                                     │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│ Iteration 2: Action Phase                                    │
├─────────────────────────────────────────────────────────────┤
│ AI receives: ["shape-1", "shape-2", "shape-3"]             │
│ AI analyzes: "Now I'll delete each shape"                   │
│ Tool calls: [                                                │
│   deleteShape("shape-1"),                                    │
│   deleteShape("shape-2"),                                    │
│   deleteShape("shape-3")                                     │
│ ]                                                            │
│ Executes: All shapes deleted successfully                    │
│ Result → Feed back to AI                                     │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│ Iteration 3: Completion Phase                                │
├─────────────────────────────────────────────────────────────┤
│ AI receives: All deletions successful                        │
│ AI analyzes: "Task complete"                                │
│ Tool calls: []                                               │
│ Response: "I've deleted 3 green shapes"                     │
└─────────────────────────────────────────────────────────────┘
```

**Key Components:**

1. **Tool Categories:**

   - **Query Tools:** Return data, require follow-up (findShapesByColor, findShapesByType, getCanvasState, getSelectedShapes)
   - **Action Tools:** Perform operations, usually terminal (create, move, delete, style, layout)

2. **Conversation Context:**

   - Full OpenAI message history maintained across iterations
   - Tool results stored as `role: "tool"` messages
   - AI sees complete reasoning chain

3. **Iteration Control:**
   - Max 5 iterations per command (prevents infinite loops)
   - Auto-stop when no more tool calls returned
   - Auto-stop after all action tools complete successfully

---

#### 4.4.2 Tool Result Format

All tools return structured results for AI feedback:

```typescript
interface ToolExecutionResult {
  tool: string; // Tool name
  success: boolean; // Execution status
  message: string; // Human-readable message
  data?: any; // Query results (for query tools)
  objectsCreated?: string[]; // IDs of created objects
  objectsModified?: string[]; // IDs of modified objects
  error?: string; // Error message if failed
}
```

**Query Tool Example:**

```json
{
  "tool": "findShapesByColor",
  "success": true,
  "message": "Found 3 shape(s) with color #10B981",
  "data": {
    "shapeIds": ["shape-1", "shape-2", "shape-3"],
    "shapes": [
      {
        "id": "shape-1",
        "type": "rectangle",
        "x": 100,
        "y": 200,
        "color": "#10B981"
      },
      {
        "id": "shape-2",
        "type": "circle",
        "x": 300,
        "y": 400,
        "color": "#10B981"
      },
      {
        "id": "shape-3",
        "type": "star",
        "x": 500,
        "y": 600,
        "color": "#10B981"
      }
    ],
    "count": 3
  }
}
```

**Action Tool Example:**

```json
{
  "tool": "deleteShape",
  "success": true,
  "message": "Deleted shape shape-1",
  "objectsModified": ["shape-1"]
}
```

---

#### 4.4.3 Updated System Prompt Guidelines

**ReAct Instructions for AI:**

```
Multi-Step Reasoning (ReAct Pattern):
You can perform operations in multiple steps. The results of each step will be provided for your next decision.

Query Tools (gather information first):
- findShapesByColor(color) → Returns array of shape IDs matching the color
- findShapesByType(type) → Returns array of objects matching the type
- getCanvasState() → Returns all canvas objects
- getSelectedShapes() → Returns currently selected object IDs

Action Tools (perform operations on found objects):
- All creation, manipulation, styling, and layout tools

Example Workflows:

User: "Delete all green shapes"
Step 1: Call findShapesByColor("green") → Receive shape IDs
Step 2: Call deleteShape() for each ID → Delete them
Step 3: Respond with confirmation message

User: "Move all circles 100px to the right"
Step 1: Call findShapesByType("circle") → Receive circle objects
Step 2: For each circle, call moveShape(id, x + 100, y)
Step 3: Confirm completion

User: "Make all small rectangles red"
Step 1: Call findShapesByType("rectangle") → Receive rectangles
Step 2: Filter results for width < 100 && height < 100
Step 3: Call updateShapeStyle() for each small rectangle
Step 4: Confirm completion

Important:
- You have up to 5 iterations to complete a task
- Always use query tools first when dealing with "all X" or "find X"
- Provide clear progress updates: "Found 5 circles, now moving them..."
- If task is too complex for 5 steps, ask user to break it down
```

---

#### 4.4.4 Loop Control & Safety

**Max Iterations:** 5 per command

**Rationale:**

- Iteration 1: Initial query
- Iteration 2-3: Primary actions
- Iteration 4-5: Follow-up actions or verification
- Prevents infinite loops from AI reasoning errors
- Sufficient for 95% of multi-step operations

**Stop Conditions:**

1. **Natural Completion:** AI returns no tool calls (task done)
2. **Max Iterations:** 5 iterations reached (warn user)
3. **Error Threshold:** 2 consecutive failed tool calls (abort)
4. **User Cancellation:** User stops the command mid-execution

**Timeout:** 60 seconds total (10-12 seconds per iteration)

---

#### 4.4.5 User Experience

**Progress Indicators:**

- **Iteration 1:** "Processing your request..." (standard)
- **Iteration 2+:** "Processing step 2..." (shows multi-step progress)
- **Completion:** "Completed in 3 steps" (summary)

**Progress Visibility:**

- **Requesting user:** Sees "Step X/Y" progress
- **Other users:** See standard "AI is working..." (keeps UI clean)

**Error Messages:**

```
- "Found 0 green shapes. Current shapes: 2 blue rectangles, 1 red circle."
- "Operation partially completed (5/8 shapes). Please select remaining shapes manually."
- "Task too complex for automatic execution. Try: 'Delete green circles' then 'Delete green rectangles' separately."
```

---

#### 4.4.6 Performance Characteristics

**Latency:**

| Command Type                  | Iterations | Latency | Token Usage  |
| ----------------------------- | ---------- | ------- | ------------ |
| Single-step (create, move)    | 1          | 1-2s    | ~750 tokens  |
| Query-then-act (delete all X) | 2-3        | 3-6s    | ~2000 tokens |
| Complex multi-step            | 3-5        | 6-10s   | ~3500 tokens |

**Cost Impact:**

- Single-step commands: No change (~$0.008/command)
- Multi-step commands: 3-4x increase (~$0.028/command)
- Average across all commands: ~2x increase (~$0.015/command)

**Acceptable for Phase 3** (personal project, quality > cost)

---

#### 4.4.7 Example Commands Enabled by ReAct

**Simple Query-Act:**

- "Delete all green shapes"
- "Move all circles to the center"
- "Make all rectangles larger"
- "Change all red shapes to blue"

**Conditional Operations:**

- "If there are any green circles, delete them"
- "Find all small shapes and arrange them in a row"
- "Select all shapes created by Sarah"

**Multi-Stage Operations:**

- "Find all blue shapes, align them left, then distribute them vertically"
- "Get all circles, make them red, then move them to the top"
- "Find rectangles larger than 200px, change their color to green, then rotate them 45 degrees"

**Smart Filtering:**

- "Delete all shapes except the blue ones"
- "Move only the large circles to the right"
- "Find green rectangles taller than 100px and make them red"

---

#### 4.4.8 Conversation Context Management

**OpenAI Message Format:**

```javascript
[
  { role: "system", content: "You are an AI assistant..." },
  { role: "user", content: "Delete all green shapes" },
  { role: "assistant", content: null, tool_calls: [{name: "findShapesByColor", ...}] },
  { role: "tool", tool_call_id: "call_1", name: "findShapesByColor", content: '{"shapeIds": ["shape-1", "shape-2"]}' },
  { role: "assistant", content: null, tool_calls: [{name: "deleteShape", ...}] },
  { role: "tool", tool_call_id: "call_2", name: "deleteShape", content: '{"success": true}' },
  { role: "assistant", content: "I've deleted 2 green shapes." }
]
```

**Context Window Management:**

- Keep last 10 user-assistant exchanges (~20 messages)
- Include all tool results from current command
- Summarize old tool results to save tokens
- Full reset after command completion

---

#### 4.4.9 Integration with Existing System

**No Breaking Changes:**

✅ Single-step commands work exactly as before
✅ Existing tools unchanged (just return more detailed results)
✅ Canvas Context functions unchanged
✅ Real-time sync unchanged
✅ Offline queue unchanged

**Additive Enhancements:**

- Tools now return structured results
- Client tracks conversation across iterations
- Backend accepts conversation history
- System prompt includes ReAct guidelines

**Backward Compatibility:**

```typescript
// Old behavior (still works)
User: "Create a red circle"
→ 1 iteration, immediate response

// New behavior (seamless)
User: "Delete all red circles"
→ 2-3 iterations, multi-step execution
```

---

#### 4.4.10 Testing & Validation

**Unit Tests:**

- Query tool result format validation
- Action tool result format validation
- Loop termination conditions
- Max iteration handling
- Error propagation

**Integration Tests:**

- Single query → multiple actions
- Multiple queries → single action
- Query → action → verify pattern
- Error recovery during loop
- Timeout handling

**E2E Test Scenarios:**

| Command                                  | Expected Iterations | Expected Outcome    |
| ---------------------------------------- | ------------------- | ------------------- |
| "Create a red circle"                    | 1                   | Circle created      |
| "Delete all green shapes"                | 2                   | Query → Delete      |
| "Move all circles right"                 | 2-3                 | Query → Move each   |
| "Find blue rectangles and make them red" | 2-3                 | Query → Update each |
| "Arrange all stars in a grid"            | 2-3                 | Query → Create grid |

---

**Success Criteria**

✅ Query-dependent commands work reliably
✅ Multi-step commands complete in <10 seconds
✅ No infinite loops (max 5 iterations enforced)
✅ Single-step commands not impacted (no latency regression)
✅ Clear progress feedback to users
✅ Graceful error handling and recovery

---

**Risks & Mitigation**

| Risk                | Impact | Probability | Mitigation                                 |
| ------------------- | ------ | ----------- | ------------------------------------------ |
| AI infinite loops   | High   | Low         | Hard 5-iteration limit                     |
| Increased latency   | Medium | High        | Show progress, optimize token usage        |
| Higher API costs    | Medium | High        | Acceptable for Phase 3, can optimize later |
| Complex debugging   | Medium | Medium      | Comprehensive logging, visualization tools |
| AI reasoning errors | High   | Low         | Validation on each tool result             |

---

## Section 5: User Interface Design

### 5.1 AI Chat Panel

**Location:** Right sidebar (collapsible, 400px wide)

**Layout:**

```
┌─────────────────────────┐
│ AI Assistant        [x] │
├─────────────────────────┤
│                         │
│  [Chat History]         │
│  Scrollable             │
│  - User messages        │
│  - AI responses         │
│  - Success/error states │
│                         │
├─────────────────────────┤
│ [Type your command...]  │
│ [→]                     │
└─────────────────────────┘
```

**Features:**

- **Toggle button** in header: ⚡ or 🤖 icon labeled "AI Assistant"
- **Message history** persisted in localStorage per user (not synced to team)
- **Markdown support** for AI responses (bold, lists, code)
- **Loading states:** Typing indicator "AI is thinking..." with animated dots
- **Error handling:** Red toast notifications for failures
- **Command suggestions:** 5-8 examples shown when chat empty

**Command Suggestions (Always Visible When Empty):**

- "Create a red circle at 100, 200"
- "Build a login form"
- "Arrange selected shapes horizontally"
- "Create a 3x3 grid of squares"
- "Change the blue rectangle to green"
- "Make a navigation bar with 4 menu items"
- "Align all circles to the left"
- "Create a card layout with title and description"

### 5.2 Canvas Visual Feedback

**AI Operation Indicators:**

**Simple Progress Indicator (Requesting User Only):**

- Small loading spinner appears in chat panel during AI processing
- Message shows: "AI is thinking..." with animated dots
- Only visible to the user who issued the command
- Other users see no indication—objects simply appear as they're created

**Attribution Badge (Existing System):**

- Reuses existing "Last edited by" tooltip system from Phase 2
- For AI-created objects, shows: "Created by AI Agent (requested by Sarah Chen), 2m ago"
- Appears on hover over any AI-generated object
- No special visual indicators (no ⚡ icons or highlights)
- Keeps UI clean and consistent with manual edits

### 5.3 Command History Panel

**Location:** Expandable section within AI chat panel

**Features:**

- Shows last 20 commands across all users
- Format: `[12:45 PM] Sarah: "Create a login form" ✓`
- Status indicators: ✓ (success), ✗ (error), ⏳ (in progress)
- Click to replay command (re-executes with current canvas state)
- Filter by user, date range
- Persistence: Stored per canvas in Firebase (not per user)

**Use Cases:**

- Onboarding: New team members see what commands built the design
- Learning: Users discover new command patterns
- Debugging: Track which AI operations created specific objects

---

## Section 6: Performance Requirements

### 6.1 Performance Targets

**Latency (End-to-End):**

- Simple commands (single-step): <2 seconds
  - User types → API call → GPT-4 → validation → execution → sync
- Complex commands (multi-step): <5 seconds
  - Multi-step planning, sequential tool execution

**Reliability:**

- Success rate: >95% for valid commands
- Error recovery: <3 retries for transient failures
- Graceful degradation: If AI unavailable, show friendly error + manual fallback

### 6.2 Token Optimization

**Canvas State Summarization:**

- **<100 objects:** Send full state (~2000 tokens max)
- **100+ objects:** Send selected objects + recently created only (~500 tokens)
- Reduces token usage by 70-90% for large canvases

**Context Structure:**

```typescript
// Small canvas (<100 objects) - full state
{
  "objects": [...all objects with full properties...],
  "selectedIds": ["obj-1", "obj-2"],
  "viewport": { "zoom": 1.0, "panX": 0, "panY": 0 }
}

// Large canvas (100+ objects) - summarized
{
  "objectCount": 150,
  "objectTypes": { "rectangle": 80, "circle": 50, "text": 20 },
  "selectedObjects": [...full properties of selected only...],
  "recentlyCreated": [...last 5 objects created...]
}
```

**Note:** No rate limiting or quota tracking for personal project use

---

## Section 7: Error Handling & Edge Cases

### 7.1 Invalid Commands

**Scenario:** User types ambiguous or nonsensical command

**AI Response Pattern:**

```
"I'm not sure what you mean by '[command]'. Did you mean:
- Create a shape?
- Move an existing object?
- Arrange multiple objects?

Try commands like: 'Create a red circle' or 'Move the blue square to the center'"
```

**Examples:**

- User: "make it do the thing"
  - AI: "I need more details. What would you like me to create or modify?"
- User: "fix the layout"
  - AI: "Which objects would you like me to adjust? You could try: 'Align selected shapes' or 'Distribute them evenly'"

### 7.2 Validation Errors

**Out-of-Bounds Position:**

- Command: "Create a circle at position 20000, 30000"
- Response: "Position (20000, 30000) is outside canvas bounds (0-10000). Placing at canvas center (5000, 5000) instead."

**Invalid Color:**

- Command: "Make it banana yellow"
- Response: "I'll use a yellow color (#F59E0B) for this. You can specify hex codes like #FFFF00 for precise colors."

**Non-Existent Object Reference:**

- Command: "Move the purple triangle to the top"
- Response: "I don't see a purple triangle on the canvas. Current objects: 2 blue rectangles, 1 red circle. Would you like to create one?"

**Conflicting Command:**

- Command: "Delete everything and create a circle"
- Response: "⚠️ This will delete 15 objects. Are you sure? Reply 'yes' to confirm or give me a different command."

### 7.3 AI Operation Failures

**Timeout (>30 seconds):**

- Show inline message in chat: "AI operation is taking longer than expected. This might be a complex command."
- User can continue chatting or wait for response
- If command eventually succeeds, objects appear and chat shows success message

**Network Error During Execution:**

- Show toast: "Lost connection while creating objects. Reconnecting..."
- Retry automatically up to 3 times with exponential backoff
- If all retries fail: "Couldn't complete AI command. Please check your connection and try again."
- Partial changes remain on canvas (via existing offline queue)

---

## Section 8: Command History & Replay

**Feature:** Per-canvas command history visible to all team members

**Location:** Expandable section in AI chat panel

**Display Format:**

```
Command History (Last 20)
─────────────────────────────
[12:45 PM] Sarah: "Create a login form" ✓
[12:47 PM] Marcus: "Make the button bigger" ✓
[12:50 PM] Sarah: "Add a footer with 3 links" ✓
[1:15 PM] Alex: "Create a pricing table" ✗ (error)
```

**Features:**

- Click command → replay with current canvas state
- Status icons: ✓ success, ✗ error, ⏳ in progress
- Filter by user, date range
- Shows execution time (e.g., "2.3s")
- Stored in Firebase: `/canvases/default/aiCommandHistory/`

**Use Cases:**

- **Onboarding:** New team members learn what commands built the design
- **Learning:** Discover new command patterns from teammates
- **Debugging:** Track which AI operations created specific objects
- **Reproducibility:** Replay successful commands on new canvases

---

## Database Schema Changes

### Updated Firebase Structure

```json
{
  "canvases": {
    "default": {
      "objects": {
        "{objectId}": {
          // ... existing fields from Phase 2
          "createdBy": "user-123" | "ai-agent",
          "aiOperationId": "ai-op-456", // Groups objects from same AI command
          "aiRequestedBy": "user-123" // If AI-created, who requested it
        }
      },
      "aiCommandHistory": {
        "{commandId}": {
          "command": "Create a login form",
          "userId": "user-123",
          "userName": "Sarah Chen",
          "timestamp": 1697123456789,
          "status": "success" | "error" | "cancelled",
          "objectsCreated": ["obj-1", "obj-2", "obj-3"],
          "objectsModified": ["obj-4", "obj-5"],
          "executionTime": 2300, // milliseconds
          "tokensUsed": { "input": 450, "output": 120 },
          "errorMessage": null
        }
      }
    }
  }
}
```

**Migration Strategy:**

- Existing objects automatically get `createdBy: "user-{userId}"` (backfill)
- No data loss, backward compatible
- AI fields only populated for new AI operations

---

## API Specification

### POST /api/ai-chat

**Endpoint:** Server-side function (Vercel Serverless or Firebase Functions)

**Request Body:**

```json
{
  "message": "Create a red circle at 100, 200",
  "canvasId": "default",
  "userId": "user-123",
  "conversationHistory": [
    { "role": "user", "content": "Create a blue square" },
    {
      "role": "assistant",
      "content": "Created a blue square at canvas center."
    }
  ]
}
```

**Response (Success):**

```json
{
  "success": true,
  "toolCalls": [
    {
      "tool": "createShape",
      "parameters": {
        "type": "circle",
        "x": 100,
        "y": 200,
        "width": 100,
        "height": 100,
        "color": "#EF4444"
      }
    }
  ],
  "aiResponse": "Created a red circle at position (100, 200).",
  "aiOperationId": "ai-op-789",
  "executionTime": 1200,
  "tokensUsed": { "input": 450, "output": 120 }
}
```

**Response (Error):**

```json
{
  "success": false,
  "error": "INVALID_COMMAND",
  "message": "I couldn't understand that command. Try: 'Create a red circle' or 'Move the blue square to the center'",
  "suggestions": [
    "Create a [color] [shape]",
    "Move the [object] to [position]",
    "Create a login form"
  ]
}
```

**Error Codes:**

- `INVALID_COMMAND` - AI couldn't parse the command
- `VALIDATION_ERROR` - Tool parameters failed validation
- `TIMEOUT` - AI took >30 seconds to respond
- `NETWORK_ERROR` - OpenAI API unavailable
- `AUTHENTICATION_ERROR` - Invalid or missing Firebase token

---

## Success Metrics

### Functional Completeness

**Must-Have (P0):**

- ✅ AI supports 6 command categories (20+ specific commands)
- ✅ Simple commands execute in <2 seconds end-to-end
- ✅ Complex commands execute in <5 seconds
- ✅ All users see AI-generated content in real-time (<100ms)
- ✅ Multiple users can use AI simultaneously without conflicts (per-canvas queue)
- ✅ Commands succeed >95% of the time
- ✅ Canvas state optimization reduces tokens by 70%+ for large canvases
- ✅ Command history persists and displays correctly
- ✅ AI executes via existing Canvas Context (client-side tool execution)

**Should-Have (P1):**

- ✅ AI handles ambiguous commands with inline clarifying questions
- ✅ Error messages are helpful and actionable
- ✅ Attribution badges clearly indicate AI-created objects (using existing system)
- ✅ Command suggestions help new users discover capabilities
- ✅ Dynamic generation of complex UI layouts (login forms, nav bars, etc.)

**Nice-to-Have (P2):**

- 🔄 Command replay from history
- 🔄 Advanced query commands (filters, aggregations)
- 🔄 Multi-language support (English only in Phase 3)
- 🔄 Undo system for AI operations (deferred to Phase 4)

### Quality Benchmarks

**Performance:**

- ✅ Simple commands <2s latency (p95)
- ✅ Complex commands <5s latency (p95)
- ✅ Token processing <1s (p95)
- ✅ AI operations maintain 60 FPS during execution
- ✅ Canvas state summarization <100ms

**Reliability:**

- ✅ >95% success rate for valid commands
- ✅ Zero conflicts in multi-user scenarios (per-canvas queue)
- ✅ Graceful error handling for all edge cases
- ✅ Inline error messages with actionable suggestions

**Token Efficiency:**

- ✅ Small canvases (<100 objects): ~2000 tokens max
- ✅ Large canvases (100+ objects): ~500 tokens via summarization
- ✅ 70-90% reduction in token usage for large canvases

### User Experience

**Usability:**

- ✅ First-time users successfully issue commands within 30 seconds
- ✅ Command suggestions clicked >30% of the time
- ✅ Error messages lead to successful retries >80% of time
- ✅ Users find AI chat panel within 10 seconds
- ✅ Simple, clean UI with minimal visual distractions

**Adoption (Personal Project Goals):**

- ✅ AI successfully executes common design patterns (login forms, nav bars)
- ✅ Complex commands dynamically generate appropriate layouts
- ✅ Multi-user collaboration remains smooth during AI operations
- ✅ AI-generated content syncs identically to manual edits

---

## Risk Management

### High-Risk Areas & Mitigation

| Risk                                         | Probability | Impact | Mitigation                                         | Contingency                                    |
| -------------------------------------------- | ----------- | ------ | -------------------------------------------------- | ---------------------------------------------- |
| **AI hallucination creates invalid objects** | Medium      | High   | Strict Zod validation on all tool parameters       | Show validation error, ask user to rephrase    |
| **Cost overruns from large canvases**        | Low         | Medium | State summarization (500 tokens max for 100+ objs) | Monitor costs, adjust summarization if needed  |
| **Multi-user command conflicts**             | Low         | High   | Per-canvas FIFO queue                              | Users see inline message about queued commands |
| **OpenAI API outages**                       | Low         | High   | Exponential backoff retry (3 attempts)             | Show friendly error, enable manual fallback    |
| **Dynamic templates inconsistent**           | Medium      | Medium | Clear guidelines in system prompt                  | Add few-shot examples if quality is poor       |
| **Complex commands fail silently**           | Medium      | Medium | Show inline progress for requesting user           | Partial results shown, user can retry/modify   |
| **Client-side tool execution vulnerable**    | Low         | Medium | Validate all parameters before execution           | Server-side validation as backup               |

---

## Out of Scope (Phase 3)

### Explicitly Not Included:

❌ **Undo for AI operations** - Deferred to Phase 4 (too complex for initial implementation)
❌ **Rate limiting/quotas** - Not needed for personal project use
❌ **Advanced visual feedback** - No ghost previews, progress bars, or highlight animations (keeping UI simple)
❌ **Image generation** - AI creates shapes only, not raster images
❌ **Style transfer** - No "make this look like X" commands
❌ **Component library integration** - No pre-built component imports
❌ **AI-suggested improvements** - Proactive suggestions deferred to Phase 4
❌ **Natural language search** - "Find all login forms" deferred
❌ **Voice input** - Text-only commands in Phase 3
❌ **Multi-language support** - English only, i18n in Phase 4
❌ **AI-powered layout optimization** - Manual layout only
❌ **Collaborative AI brainstorming** - Single-user AI interaction only
❌ **AI commenting/feedback** - AI doesn't critique designs
❌ **Custom AI training** - Generic GPT-4, no fine-tuning
❌ **Batch operations** - AI processes one command at a time

**Rationale:** Phase 3 focuses on core conversational AI capabilities. Advanced features require additional infrastructure and validation.

---

## Technical Debt & Future Improvements

### Known Limitations (Accept for Phase 3)

**Context Window:**

- We summarize large canvases (100+ objects) to ~500 tokens
- Very large canvases (>1000 objects) may lose some context
- Mitigation: Focus on selected objects + recently created

**Conversation Memory:**

- Chat history limited to last 10 exchanges (stored locally)
- Long conversations may lose early context
- Mitigation: Each command includes full canvas state context

**Tool Limitations:**

- No batch operations (e.g., "create 100 circles")
- Complex SVG paths not supported
- No image uploads or raster manipulation
- No undo system for AI operations (defer to Phase 4)

**Client-Side Execution:**

- Tools executed on client means user must remain online during execution
- If user disconnects, operations queue via existing offline system
- Server doesn't directly manipulate Firebase (relies on client)

### Phase 4 Roadmap Preview

**Undo/Redo System:**

- Full undo/redo for all operations (manual + AI)
- Grouped undo for AI operations (undo entire "create login form" command)
- History panel showing all canvas changes

**Advanced AI Features:**

- AI-suggested improvements ("This layout could use more spacing")
- Natural language search ("Show me all login forms created last week")
- Voice input for commands
- Multi-language support (Spanish, French, German, Chinese)
- AI-powered layout optimization ("Arrange this optimally")
- Batch operations ("Create 50 randomly colored circles")

**Enhanced Collaboration:**

- Collaborative AI brainstorming sessions
- AI moderator for design reviews
- AI-generated design system documentation

**Optimization & Polish:**

- Hard-coded component templates (faster, more consistent than dynamic)
- Server-side tool execution (more secure, works offline)
- Fine-tuned model for canvas-specific operations
- Caching frequent command patterns

---

## Implementation Timeline

### Phase 3 Estimated Duration: 4-5 Weeks (Simplified Scope)

**Week 1: Infrastructure Setup (PR #23)**

- Firebase Cloud Functions setup
- OpenAI API integration (GPT-4 Turbo)
- Tool definitions and validation (16 tools, Zod schemas)
- Server-side API endpoint `/api/ai-chat`
- Canvas state summarization logic

**Week 2: Client Integration (PR #24)**

- AI chat panel component (right sidebar)
- Command input and message history
- Client-side tool executor (calls Canvas Context functions)
- Per-canvas command queue
- Basic error handling

**Week 3: Command Implementation (PRs #25-26)**

- **PR #25:** Simple commands (create, move, resize, delete, style)
- **PR #26:** Layout commands (arrange, align, distribute, grid)
- Query and selection commands
- Dynamic complex command generation (login forms, nav bars)

**Week 4: Testing & Polish (PR #27)**

- Multi-user testing (queue conflicts, simultaneous AI usage)
- Error handling refinement (inline chat, helpful messages)
- Command suggestions and help content
- Performance testing (latency, token usage)

**Week 5: Documentation & Deployment (PR #28)**

- Command history panel
- User documentation (command reference, examples)
- Final testing and bug fixes
- Production deployment

### Milestones

**Milestone 1 (Week 1):** Firebase Functions operational, test API calls work
**Milestone 2 (Week 2):** UI complete, simple commands execute end-to-end
**Milestone 3 (Week 3):** All command categories working, dynamic templates functional
**Milestone 4 (Week 5):** Production-ready, multi-user tested, deployed

---

## Testing Strategy

### Functional Testing

**Command Validation (100+ Test Cases):**

- All 20+ command types execute correctly
- Parameter validation catches errors
- Ambiguous commands trigger clarifications
- Edge cases handled gracefully

**Multi-User Testing:**

- 3+ users issuing AI commands simultaneously
- Command queueing prevents conflicts
- All users see AI operations in real-time
- Attribution shows correctly for all users

**Integration Testing:**

- AI tools integrate with existing Canvas Context
- Firebase sync works identically to manual edits
- Offline queue handles AI operations
- Undo system works for AI operations

### Performance Testing

**Latency Benchmarks:**

- 50 simple commands → p95 <2s
- 50 complex commands → p95 <5s
- Large canvas (500+ objects) → summarization <100ms
- Token processing → p95 <1s

**Load Testing:**

- 10 concurrent users issuing commands
- 100 commands/hour sustained load
- Rate limiting enforces correctly
- No performance degradation over time

**Token Testing:**

- 100 test commands across canvas sizes
- Verify summarization reduces tokens by 70%+ for large canvases
- Token usage tracking accurate

### User Acceptance Testing

**Personal Testing Goals:**

- Successfully execute all 20+ command types
- Dynamic templates generate reasonable layouts
- Multi-user collaboration remains smooth
- Error messages are clear and helpful
- Command history displays correctly

**Edge Case Testing:**

- Large canvases (100+ objects) with summarization
- Empty canvases (no context)
- Network failures during execution
- Concurrent edits (AI + manual from multiple users)
- Ambiguous commands requiring clarification

---

## Documentation Requirements

### User-Facing Documentation

**In-App Help:**

- Command suggestions (always visible in empty chat)
- Tooltip help on first AI button click
- Error messages with actionable guidance
- "Learn More" links in chat panel

**External Documentation:**

- Getting started guide (5-minute tutorial)
- Command reference (all 20+ commands with examples)
- Best practices guide (effective prompting)
- Troubleshooting FAQ

### Developer Documentation

**Architecture Documentation:**

- AI system architecture diagram
- Tool definition reference
- API endpoint specifications
- Database schema changes

**Code Documentation:**

- Inline comments for complex logic
- JSDoc for all public functions
- README updates with Phase 3 features
- Deployment guide for AI features

---

## Conclusion

Phase 3 transforms CollabCanvas from a collaborative design tool into an AI-powered design assistant, dramatically accelerating common workflows while maintaining the real-time collaboration that defines the platform.

**Key Success Factors:**

1. **Simplicity:** Clean implementation using existing Canvas Context (client-side execution)
2. **Reliability:** >95% success rate with strict parameter validation
3. **Performance:** <2s latency for simple commands, <5s for complex
4. **Transparency:** Clear attribution using existing "last edited by" system
5. **Flexibility:** Dynamic template generation adapts to user intent

**Key Innovation:**

CollabCanvas leverages conversational AI with **zero special-case synchronization**—AI operations use the same Canvas Context functions as manual edits, ensuring perfect real-time collaboration.

**Benefits:**

- 5-10x faster creation of common layouts (login forms, nav bars)
- Natural language design exploration ("create a blue circle")
- Reduced cognitive load (describe intent vs. manual construction)
- Seamless team collaboration (AI operations sync identically to manual edits)
- Simple, maintainable architecture (no complex undo, rate limiting, or visual feedback)

**Post-Phase 3 Vision:**

With Phase 3 complete, CollabCanvas establishes a foundation for AI-assisted design. Phase 4 will add:

- Full undo/redo system (grouped undo for AI operations)
- AI-suggested improvements and layout optimization
- Natural language search across canvas history
- Voice input and multi-language support

---

## Appendix: Example User Flows

### Example 1: Designer Creates Login Form with AI

**Flow:**

1. Sarah opens CollabCanvas, clicks ⚡ "AI Assistant" in header
2. AI chat panel slides open from right
3. Sarah types: "Create a login form"
4. AI responds: "Creating login form..." (progress: 1/7 steps)
5. Objects appear progressively: title → username label → input field → password label → input field → button → link
6. Each object pulses green briefly as created
7. AI responds: "✓ Created a login form with username, password fields, and submit button."
8. Sarah: "Make the button bigger"
9. AI: "✓ Increased button size from 150x40 to 200x50."
10. **Marcus sees all changes in real-time** on his screen
11. Marcus hovers over button → sees attribution: "AI Agent (requested by Sarah Chen)"

**Time:** 2 minutes vs. 15 minutes manual

---

### Example 2: Team Collaborates with AI

**Flow:**

1. Sarah issues AI command: "Create a navigation bar with 4 menu items"
2. AI starts executing (shows in queue for Marcus)
3. Marcus types: "Add a logo placeholder on the left"
4. Marcus sees: "Command queued (1 ahead of you)"
5. Sarah's nav bar completes → Marcus's command executes
6. Both operations sync to entire team
7. Alex (third teammate) sees both changes appear
8. Alex: "Align all menu items to the right"
9. AI executes, everyone sees update

**Result:** 3 users collaborate seamlessly with AI, no conflicts

---

### Example 3: Error Handling and Recovery

**Flow:**

1. User: "move the purple thing to the top"
2. AI: "I don't see a purple object on the canvas. Current objects: 2 blue rectangles, 1 red circle. Would you like to create a purple shape?"
3. User: "yes, make a purple square"
4. AI: "✓ Created a purple square at canvas center (5000, 5000)."
5. User: "now move it to position 50000, 50000"
6. AI: "⚠️ Position (50000, 50000) is outside canvas bounds (0-10000). Moving to canvas top-right corner (9500, 500) instead."
7. User sees purple square move to top-right
8. User: "perfect, thanks!"

**Result:** AI gracefully handles ambiguity and invalid inputs

---

## Appendix: Command Reference Quick Guide

### Creation Commands

- `Create a [color] [shape] at [x], [y]`
- `Add a text that says "[text]" at [position]`
- `Make a [width]x[height] [color] rectangle`

### Manipulation Commands

- `Move the [object reference] to [x], [y]`
- `Resize the [object] to be [size] / [percentage]`
- `Rotate the [object] [degrees] degrees`
- `Change the [object] to [color]`
- `Delete the [object]`

### Layout Commands

- `Arrange [objects] in a [horizontal/vertical] row with [spacing]`
- `Create a [rows]x[cols] grid of [objects]`
- `Align [objects] to the [left/center/right/top/middle/bottom]`
- `Distribute [objects] evenly [horizontally/vertically]`

### Complex Commands

- `Create a login form`
- `Build a navigation bar with [N] menu items: [item1, item2, ...]`
- `Make a card layout with [components]`
- `Create a pricing table with [N] columns`

### Query Commands

- `How many [shapes] are on the canvas?`
- `What color is the [object]?`
- `List all objects created by [user]`

### Selection Commands

- `Select all [color] [shapes]`
- `Select the [largest/smallest] [shape]`
- `Clear selection`
